1. $match:
	db.articles.aggregate( [
  { $match: { $or: [ { score: { $gt: 70, $lt: 90 } }, { views: { $gte: 1000 } } ] } },
  { $group: { _id: null, count: { $sum: 1 } } }
] );
	输出：
		{ "_id" : null, "count" : 5 }

2.$sort $limit $skip 在管道中执行顺序：
	（1）默认下会 按照指定的顺序执行：
	即 以下会先截取10条数据，然后再跳过5条， 最后再对剩余的5条数据进行排序
test>db.numbs.aggregate([{$limit:10},{$skip:5},{$sort:{num1:-1}}
{ "_id" : 8, "name" : "SPzjcGLOt", "num1" : 95, "num2" : 9 }
{ "_id" : 7, "name" : "exBe", "num1" : 93, "num2" : 4 }
{ "_id" : 6, "name" : "YPTLomeFZEc", "num1" : 90, "num2" : 11 }
{ "_id" : 10, "name" : "rSaUQpaoFZ", "num1" : 42, "num2" : 10 }
{ "_id" : 9, "name" : "yQjbUJziuNI", "num1" : 15, "num2" : 11 }

	（2）当 $limit 在 $skip 之后时，则会先执行$limit, 获取 $limit +$skip 条数据，
		然后再执行 $skip 跳过指定条记录
	test>db.numbs.aggregate([{$skip:5},{$limit:3},{$sort:{num1:-1}}])
{ "_id" : 8, "name" : "SPzjcGLOt", "num1" : 95, "num2" : 9 }
{ "_id" : 7, "name" : "exBe", "num1" : 93, "num2" : 4 }
{ "_id" : 6, "name" : "YPTLomeFZEc", "num1" : 90, "num2" : 11 }

		若将$limit 放在 $skip 之前：
		test>db.numbs.aggregate([{$limit:3},{$skip:5},{$sort:{num1:-1}}])
		则会先获取 3条数据， 再跳过 5条 ，故返回空

3.$unwind :将数组拆分为 每个元素为文档：
{ "_id" : 1, "name" : "sue", "age" : 19, "finished" : [ 17, 3 ] }

test>db.users.aggregate([{$project:{name:1,age:1,finished:1}},{$unwind:"$finished"}])
{ "_id" : 1, "name" : "sue", "age" : 19, "finished" : 17 }
{ "_id" : 1, "name" : "sue", "age" : 19, "finished" : 3 }
{ "_id" : 2, "name" : "bob", "age" : 42, "finished" : 11 }
{ "_id" : 2, "name" : "bob", "age" : 42, "finished" : 25 }
{ "_id" : 2, "name" : "bob", "age" : 42, "finished" : 22 }
{ "_id" : 3, "name" : "ahn", "age" : 22, "finished" : 6 }
{ "_id" : 4, "name" : "xi", "age" : 34, "finished" : 5 }
{ "_id" : 4, "name" : "xi", "age" : 34, "finished" : 11 }	

	可以对拆分后的文档进行匹配
	test>db.authors.aggregate([
			{$unwind:"$books"},
			{$match:{books:{$regex:/^the/i}
				}
			}
		])
	输出：
{ "_id" : "Homer", "books" : "The Odyssey" }
{ "_id" : "Dante", "books" : "The Banquet" }
4. $addFields添加新的返回字段:
	可以添加多次，每次可以添加多个字段
	当 添加的字段名 与已存在的字段名重复时，会覆盖原已存在的字段值 	
	db.numbs.aggregate([
		{$addFields:{
			sum:{$add:["$num1","$num2"]	
				},
			sub:{$subtract:["$num1","$num2"]}
			}
		},
		{$addFields:{
			sub1:{$subtract:["$num2","$num1"]}
			}
		}])
5.$out 将查询的结果 保存到指定的集合中
	当指定的集合名已存在时，会覆盖原集合中的文档
	test>db.numbs.aggregate([{$project:{
			num1:1,num2:1,
			sum:{$add:["$num1","$num2"]},
			sub:{$subtract:["$num1","$num2"]}
			}},
			{$out:"calc"}
		])
	test>db.books.aggregate([{$group:{_id:"$author",books:{$push:"$title"}}},
		{$out:"authors"}])

6.mapReduce()
	需 实现两个函数 Map 函数和 Reduce 函数 
	db.books.mapReduce(
		function(){ emit(this.author,this.copies);}, //map 函数
		function(key,values) {return Array.sum(values);}, //reduce 函数
		{out:"t"} // options
	)
	输出：
{
        "result" : "t", //储存结果的collection的名字,这是个临时集合，MapReduce的连接关闭后自动就被删除了
        "timeMillis" : 624, //执行花费的时间，毫秒为单位
        "counts" : {
                "input" : 5, //满足条件被发送到map函数的文档个数
                "emit" : 5, //在map函数中emit被调用的次数，也就是所有集合中的数据总量
                "reduce" : 2,
                "output" : 2  //结果集合中的文档个数
        },
        "ok" : 1
}
map 函数必须调用 emit(key, value), 遍历 collection 中所有的记录, 将 key 与 value 传递给 Reduce 函数进行处理
	emit的第一个参数是key，就是分组的依据，
	value，可以是要统计的数据
	this表示当前文档
reduce	函数会处理每一个分组，返回 新结果中的文档的value 键名的值
options 需指定 out 来指定保存结果的集合
	query 指定筛选条件只有满足条件的文档才会调用map函数
	sort 和limit
		执行后生成一个 t 集合：
			test>db.t.find()
				{ "_id" : "Dante", "value" : 5 }
				{ "_id" : "Homer", "value" : 20 }

	
	

	finalize 接受reduce 函数返回的内容，并处理返回处理后的结果
		test>db.books.mapReduce(
			function(){var value={tit:this.title,cop:this.copies}; 
					emit(this.author,value)
				},
			function(key,val){
				var tl=[]; cp=[];
			 	for(var i=0; i<val.length; i++){
					tl[i]=val[i].tit; cp[i]=val[i].cop;
				 }  
				return {t:tl,c:cp};
				},
			{	out:"t1",
			 	finalize:function(k,reduceVal){
					return {tt:reduceVal.t,cc:Array.sum(reduceVal.c)};
						}
			})
输出：
{
        "result" : "t1",
        "timeMillis" : 156,
        "counts" : {
                "input" : 5,
                "emit" : 5,
                "reduce" : 2,
                "output" : 2
        },
        "ok" : 1
}
查询结果
test>db.t1.find()
{ "_id" : "Dante", "value" : { "tt" : [ "The Banquet", "Divine Comedy", "Eclogues" ], "cc" : 5 } }
{ "_id" : "Homer", "value" : { "tt" : [ "The Odyssey", "Iliad" ], "cc" : 20 } }

	scope:{} 分配变量， 可在map reduce finalize 函数中使用
		test>db.books.mapReduce(
			function(){var value={tit:this.title,cop:this.copies}; 
					emit(this.author,value)
				},
			function(key,val){
				var tl=[]; cp=[];
			 	for(var i=0; i<val.length; i++){
					tl[i]=val[i].tit;
					if(val[i].cop>5){
						cp[i]=val[i].cop+p1;
					}else{
						cp[i]=val[i].cop+p2;
					}
					 
				 }  
				return {t:tl,c:cp};
				},
			{	out:"t1",
			 	finalize:function(k,reduceVal){
					return {tt:reduceVal.t,cc:Array.sum(reduceVal.c)};
						},
				scope:{p1:100,p2:300}
			})

reduce 函数必须能够处理map 中emit()  映射的键值，并且可以递归处理 reduce函数本身返回的结果，
	即 第二个参数 不一定是map 中调用emit()映射的键值，也可能是reduce函数的返回值
	因此 reduce 函数可能会多次调用，且调用的时机不一定是在map函数结束后执行
		
	test>db.records.mapReduce(
			function(){
					for(var k in this){emit(k,{count:1})}
			},
			function(key,values){
					var total=0; 
					for(var i=0; i<values.length; i++){
						total+=values[i].count;
					 } 
				return {count:total};
			 },
			{out:"t2"})
输出：
{
        "result" : "t2",
        "timeMillis" : 201,
        "counts" : {
                "input" : 4,
                "emit" : 14,
                "reduce" : 5,
                "output" : 7
        },
        "ok" : 1
}
test>db.t2.find()
{ "_id" : "_id", "value" : { "count" : 4 } }
{ "_id" : "a", "value" : { "count" : 2 } }
{ "_id" : "b", "value" : { "count" : 2 } }
{ "_id" : "c", "value" : { "count" : 2 } }
{ "_id" : "d", "value" : { "count" : 2 } }
{ "_id" : "e", "value" : { "count" : 1 } }
{ "_id" : "f", "value" : { "count" : 1 } }
说明：
	例如 集合中的文档：
		{_id:3,e:27,f:24,a:62}
	在map函数中遍历 当前文档的所有键名，调用 emit()，对每个键名指定映射的键值，
	产生一些键名和键值
	在对多个文档进行映射后，产生多个类似的{键名:{count:1}} 文档，然后按照键名进行分组 
	每个键名对应的键值为 多个 {count:1}的 数组，

	然后对每个键名和键值，调用reduce 函数
	对数组的元素的count 进行累加，并将累加后的结果返回，
	继续执行，直到键值的数组中只有一个元素，并将该元素返回 即为该键名对应的键值的最后结果	

7.distinct("") 去重指定的键名：
		test>db.records.distinct("b")
		输出： [ 54, 24 ]	

8.db.posts.insertMany([
{title:"java sun",author:"jk","day":"2012-12-14","tags":["java","spring","nosql"]},
{title:"ssh2的整合",author:"cj","day":"2012-5-10","tags":["struts 2","hibernate","spring"]},
{title:"C#的高级用法",author:"zt","day":"2012-4-3","tags":["c#","sql"]},
{title:"php mongodb",author:"lx","day":"2012-12-14","tags":["php","nosql","mongodb"]}
])

test>db.posts.group({
		"key":{"day":true},
		"initial":{tags:{}}, 
		"$reduce":function(doc,prev){
					for(i in doc.tags){ 
						if(doc.tags[i] in prev.tags)
						{
							prev.tags[doc.tags[i]]++; 
						}else{
							prev.tags[doc.tags[i]]=1;
						}
					}		
				}
	})
[
        {
                "day" : "2012-12-14",
                "tags" : {
                        "java" : 1,
                        "spring" : 1,
                        "nosql" : 2,
                        "php" : 1,
                        "mongodb" : 1
                }
        },
        {
                "day" : "2012-5-10",
                "tags" : {
                        "struts 2" : 1,
                        "hibernate" : 1,
                        "spring" : 1
                }
        },
        {
                "day" : "2012-4-3",
                "tags" : {
                        "c#" : 1,
                        "sql" : 1
                }
        }
]

//使用 mapReduce 实现：

db.posts.mapReduce(
	function(){
		var value={};
		for(i in this.tags)
		{
			if(!value[this.tags[i]])
			{
				value[this.tags[i]]=1;
			}
			else
			{
				value[this.tags[i]]++;	
			}
			
		}
		emit(this.day,value);
	},
	function(key,values)
	{
		var t=values[0];
		if(!t)
		{
			t={};
		}
		for(i=1; i<values.length; i++ )
		{
			for(k in values[i])
			{
				if(t[k]==undefined)
				{
					t[k]=values[i][k];
				}
				else{
					t[k]++;
				}
			}
		}
		return t;
	},
	{"out":"tt"}

)
说明：
	(1)reduce 函数不能返回 数组， 否则会报错：

		       "errmsg" : "reduce -> multiple not supported yet",
		因此在map 函数中 定义的 value 不能为[] ,


//将分组后的数组类型 合并到一个数组
test>db.posts.aggregate([{$unwind:"$tags"},
					{$group:{_id:"$day",
							 "tags":{$push:"$tags"}
							}
					}
				])
//或：
test>db.posts.aggregate([
			{$group:{_id:"$day",
					"tags":{$push:"$tags"}
					}
			},
			{$project:
				{"res":
					{$reduce:
						{input:"$tags",
							initialValue:[],
							in:{$concatArrays:["$$value","$$this"]}
						}
					}
				}
			}
		])			
{ "_id" : "2012-5-10", "tags" : [ "struts 2", "hibernate", "spring" ] }
{ "_id" : "2012-4-3", "tags" : [ "c#", "sql" ] }
{ "_id" : "2012-12-14", "tags" : [ "java", "spring", "nosql", "php", "nosql", "mongodb" ] }


group() 使用 finilize 指定处理最后结果函数：
	db.posts.group(
		{ "key":{"day":true},
			"initial":{tags:{}}, 
			"$reduce":function(doc,prev){ 
				for(i in doc.tags){  
					if(doc.tags[i] in prev.tags)
					{
						prev.tags[doc.tags[i]]++;  
					}
					else{ prev.tags[doc.tags[i]]=1; } 
			}
		},
		"finalize":function(prev){
			var maxpopular=0; 
			for(i in prev.tags)
			{
				if(prev.tags[i] > maxpopular)
				{
					prev.tag=i;
					maxpopular=prev.tags[i];
				} 
				
			} 
			delete prev.tags; 
		}
	} )
	finalize 指定 处理 每个分组的最后的键值 函数
输出：
[
        {
                "day" : "2012-12-14",
                "tag" : "nosql"
        },
        {
                "day" : "2012-5-10",
                "tag" : "struts 2"
        },
        {
                "day" : "2012-4-3",
                "tag" : "c#"
        }
]
使用 mapReduce()实现：
db.posts.mapReduce(
	function(){
		var value={};
		for(i in this.tags)
		{
			if(!value[this.tags[i]])
			{
				value[this.tags[i]]=1;
			}
			else
			{
				value[this.tags[i]]++;	
			}
			
		}
		emit(this.day,value);
	},
	function(key,values)
	{
		var t=values[0];
		if(!t)
		{
			t={};
		}
		for(i=1; i<values.length; i++ )
		{
			for(k in values[i])
			{
				if(t[k]==undefined)
				{
					t[k]=values[i][k];
				}
				else{
					t[k]++;
				}
			}
		}
		return t;
	},
	{"out":"tt",
		"finalize":function(k,reduceVal){
			var maxcount=0;
			var s="";
			for(i in reduceVal)
			{
				if(reduceVal[i]>maxcount)
				{
					maxcount=reduceVal[i];
					s=i;
				}
			}
		return {"dt":k,"tag":s};	
		}
		
	}

)
输出：
[
        {
                "day" : "2012-12-14",
                "tag" : "nosql"
        },
        {
                "day" : "2012-5-10",
                "tag" : "struts 2"
        },
        {
                "day" : "2012-4-3",
                "tag" : "c#"
        }
]

修改副本集成员配置时的限制：
1、不能修改_id；
	当 rs.initiate() 在两个节点上执行后 ，则两个节点创建的单机节点中
		members:[{_id:0}], _id 为0，
	此时不能将其中一个节点添加到另一个节点成员：
		会报错：
			 failed with Received heartbeat from member with the same member ID as ourself: 0	
		因此需要对其中的一个节点重新初始化，
		a. 停止mongod 服务，
		b. 将 配置的 dbpath 目录下的文件全部删除
		c. 按照原来的参数重启 mongod 服务，
		d.在另一个节点 执行添加节点成员：
				rs.add("192.168.1.127:27017")
		此时192.168.1.127 节点上的mongod 服务已作为副本集 存在
	说明：
		(1)添加节点时， 若 主节点的地址为 localhost 或 127.0.0.1 时，则不能添加其他IP地址的节点
2、不能讲接收rs.reconfig命令的成员的优先级设置为 0；
3、不能将仲裁者成员变为非仲裁者成员，反正亦然；
4、不能讲 buildIndexes：false 改为 true；

批量杀死进程;
	ps -ef | grep "mongos" | grep -v grep | awk '{print $2}' | xargs kill -2

配置 分片：
	（1）启动每个配置服务器，
			启动参数：
				#数据目录
				dbpath=/usr/local/config/
				#日志文件
				logpath=/var/log/mongodb/mongodb_config.log
				#日志追加
				logappend=true
				#端口
				port = 20000
				#最大连接数
				maxConns = 50
				pidfilepath = /var/run/mongo_20000.pid
				#日志,redo log
				journal = true
				#刷写提交机制
				journalCommitInterval = 200
				#守护进程模式
				fork = true
				#刷写数据到日志的频率
				syncdelay = 60
				#storageEngine = wiredTiger
				#操作日志,单位M
				oplogSize = 1000
				#命名空间的文件大小,默认16M，最大2G。
				nssize = 16
				noauth = true
				unixSocketPrefix = /tmp
				configsvr = true 
				replSet=Test
		说明：	
			a. 在3.2版本，mongos 路由服务配置参数 configdb的方式已经变成了：
					configReplSet/<cfgsvr1:port1>	
				即必须指定 复制集名，该复制集名可以与数据服务器的复制集名不同， 故配置服务器启动时必须以 replSet 参数启动
			b. 配置服务器 需添加 configsvr 参数		
	（2）连接到其中的一个配置服务器 
		初始化配置复制集
		var config={_id:"Test",members:[{_id:0,"host":"192.168.1.102:20000"},{_id:1,host:"192.168.1.127:20000"}]}
		rs.initiate(config)
		在配置复制集前，不要连接多个配置服务器，否则在初始化时，会报错 data 不为空，	
				此时需将该配置服务器的数据目录下的文件清空
	（3）启动路由服务器 mongos
			启动参数：
				logpath=D:\Program Files\MongoDB\mongos\mongodb.log 
				logappend=true 
				quiet=true 
				port=30000
				configdb=Test/192.168.1.102:20000,192.168.1.127:20000
			其中 configdb 来指定 配置服务器的地址和端口，但需指定复制集名	
	（4）添加数据服务器为分片：
			sh.addShard("Test/192.168.1.102:27017,192.168.1.127:27017")
		可以通过新建副本集数据服务器，且副本集的名与其他分片名不同，
		然后通过 sh.addShard() 添加将新建的副本集服务器添加为分片，
			在添加第二个shard时，若出现error:test database 已经存在的错误，
			连接到第二个replica set，用db.dropDatabase()命令把test数据库给删除
			然后就可加入
	（5）查看添加的分片列表：
			admin>db.runCommand({listshards:1})
{
        "shards" : [
                {
                        "_id" : "Test",
                        "host" : "Test/192.168.1.127:27017,192.168.1.145:27017",

                        "state" : 1
                },
                {
                        "_id" : "shard2",
                        "host" : "shard2/192.168.1.145:27020,192.168.1.145:27021
",
                        "state" : 1
                }
        ],
        "ok" : 1
}
激活数据库分片：
		db.runCommand( { enablesharding : “<dbname>” } );
	admin>db.runCommand({enablesharding:"test"})
	其中 必须在admin 数据库下执行， test 表示 test 数据库
	该命令 可以让数据库跨shard，如果不执行这步，数据库只会存放在一个shard，一旦激活数据库分片，数据库中不同的collection将被存放在不同的shard上，
	但一个collection仍旧存放在同一个shard上，要使单个collection也分片，还需单独对collection作些操作	

集合 分片： 需先对该集合所在的数据库激活数据库分片
	db.runCommand( { shardcollection : “<namespace>”,key : <shardkeypatternobject> })

	 a. 分片的collection系统会自动创建一个索引（也可用户提前创建好）
 	b. 分片的collection只能有一个在分片key上的唯一索引，其它唯一索引不被允许
	test>db.adminCommand({shardCollection:"test.large",key:{_id:1}})
	 集合名必须指定全限定名	
	插入2 000 000 条数据后
test>db.printShardingStatus()
--- Sharding Status ---
  sharding version: {
        "_id" : 1,
        "minCompatibleVersion" : 5,
        "currentVersion" : 6,
        "clusterId" : ObjectId("59c073d065781507ca5bc34c")
}
  shards:
        {  "_id" : "Test",  "host" : "Test/192.168.1.127:27017,192.168.1.145:270
17",  "state" : 1 }
        {  "_id" : "shard2",  "host" : "shard2/192.168.1.145:27020,192.168.1.145
:27021",  "state" : 1 }
  active mongoses:
        "3.4.6" : 1
 autosplit:
        Currently enabled: yes
  balancer:
        Currently enabled:  yes
        Currently running:  no
                Balancer lock taken at Tue Sep 19 2017 16:49:18 GMT+0800 by Conf
igServer:rsSync
        Collections with active migrations:
                test.large started at Tue Sep 19 2017 16:49:18 GMT+0800
        Failed balancer rounds in last 5 attempts:  5
        Last reported error:  Cannot accept sharding commands if not started wit
h --shardsvr
        Time of Reported error:  Tue Sep 19 2017 10:09:20 GMT+0800
        Migration Results for the last 24 hours:
                No recent migrations
  databases:
        {  "_id" : "test",  "primary" : "Test",  "partitioned" : true }
                test.large
                        shard key: { "_id" : 1 }
                        unique: false
                        balancing: true
                        chunks:
                                Test    8
                        { "_id" : { "$minKey" : 1 } } -->> { "_id" : 2 } on : Te
st Timestamp(1, 1)
                        { "_id" : 2 } -->> { "_id" : 54676 } on : Test Timestamp
(1, 2)
                        { "_id" : 54676 } -->> { "_id" : 82014 } on : Test Times
tamp(1, 3)
                        { "_id" : 82014 } -->> { "_id" : 109352 } on : Test Time
stamp(1, 4)
                        { "_id" : 109352 } -->> { "_id" : 136690 } on : Test Tim
estamp(1, 5)
                        { "_id" : 136690 } -->> { "_id" : 164028 } on : Test Tim
estamp(1, 6)
                        { "_id" : 164028 } -->> { "_id" : 191366 } on : Test Tim
estamp(1, 7)
                        { "_id" : 191366 } -->> { "_id" : { "$maxKey" : 1 } } on
 : Test Timestamp(1, 8)

分片的块信息 保存在配置服务器的 config 数据库中，该数据库在数据服务器上不可见
	
config>show tables
actionlog
changelog 记录所有拆分和迁移操作
chunks 记录集合中所有块的信息
collections 记录所有分片集合的信息
databases 记录集群中所有数据库的信息
lockpings
locks
migrations
mongos
shards 集群中所有分片的信息
tags   系统配置分片标签，每个标签都与一个块范围相关联
version

	config>db.chunks.find()
{ "_id" : "test.large-_id_MinKey", "lastmod" : Timestamp(1, 1), "lastmodEpoch" :
 ObjectId("59c0bac43a5591d61c35d03f"), "ns" : "test.large", "min" : { "_id" : {
"$minKey" : 1 } }, "max" : { "_id" : 2 }, "shard" : "Test" }
{ "_id" : "test.large-_id_2.0", "lastmod" : Timestamp(1, 2), "lastmodEpoch" : Ob
jectId("59c0bac43a5591d61c35d03f"), "ns" : "test.large", "min" : { "_id" : 2 },
"max" : { "_id" : 54676 }, "shard" : "Test" }
{ "_id" : "test.large-_id_54676.0", "lastmod" : Timestamp(1, 3), "lastmodEpoch"
: ObjectId("59c0bac43a5591d61c35d03f"), "ns" : "test.large", "min" : { "_id" : 5
4676 }, "max" : { "_id" : 82014 }, "shard" : "Test" }
{ "_id" : "test.large-_id_82014.0", "lastmod" : Timestamp(1, 4), "lastmodEpoch"
: ObjectId("59c0bac43a5591d61c35d03f"), "ns" : "test.large", "min" : { "_id" : 8
2014 }, "max" : { "_id" : 109352 }, "shard" : "Test" }
{ "_id" : "test.large-_id_109352.0", "lastmod" : Timestamp(1, 5), "lastmodEpoch"
 : ObjectId("59c0bac43a5591d61c35d03f"), "ns" : "test.large", "min" : { "_id" :
109352 }, "max" : { "_id" : 136690 }, "shard" : "Test" }
{ "_id" : "test.large-_id_136690.0", "lastmod" : Timestamp(1, 6), "lastmodEpoch"
 : ObjectId("59c0bac43a5591d61c35d03f"), "ns" : "test.large", "min" : { "_id" :
136690 }, "max" : { "_id" : 164028 }, "shard" : "Test" }
{ "_id" : "test.large-_id_164028.0", "lastmod" : Timestamp(1, 7), "lastmodEpoch"
 : ObjectId("59c0bac43a5591d61c35d03f"), "ns" : "test.large", "min" : { "_id" :
164028 }, "max" : { "_id" : 191366 }, "shard" : "Test" }
{ "_id" : "test.large-_id_191366.0", "lastmod" : Timestamp(1, 8), "lastmodEpoch"
 : ObjectId("59c0bac43a5591d61c35d03f"), "ns" : "test.large", "min" : { "_id" :
191366 }, "max" : { "_id" : { "$maxKey" : 1 } }, "shard" : "Test" }


选择片键：

片键规则和指导方针：

    1). 片键限制：片键不可以是数组。文档一旦插入，其片键就无法修改了。要修改文档的片键值，就必须先删除文档。

    2). 片键的势：选择一个值会变化的的键非常重要，即值很多，随着数据量的增大可以分出更多的片键。分片在势比较高的字段上性能更佳
	1.升序片键：
		使用如时间戳或者objectId一类的字段来分片，当数据较多时，再次插入数据会 进行对当前块进行分割，
		在分割后 只会在最后一块插入数据，这种情况会一直持续下去，这就造成了一个单一且不可分散的热点
	2.随机片键：
		采用一个取值随机的字段来做分片，但是随着数据量越来越大，他会越来越慢
		现在假设我们非常忙而分片2上的一个块填满并分裂了，配置服务器注意到分片2比分片1多出了10个块并判定应该抹平分片间的差距，
		这样MongoDB就需要随机加载5个块的数据到内存中并发给片1，考虑到数据序列的随机性，一般情况下这些数据当前可能没有在内存中，
		所以此时的MongoDB会给RAM带来更大的压力，而且还会引发大量的磁盘IO
	另外，片键上必须有索引，因此如果选择了从不依据索引查询的随机键，基本上可以说浪费了一个索引
	3.小基数片键：
		选择了一个基数很小的片键，最终会得到一堆巨大无法移动也不能分割的块，因为相同的片键值必须保存在同一个块中
	4.组合片键：

		{coarselyAscending:1,search:1}这样的组合片键来实现，
		其中coarselyAscending的每个值最好能对应几十到几百个数据块，
		而search则应当是应用程序通常都会一句其进行查询的字段
		既能把我们正在读写的数据保持在内存中，又可以均衡的分散在集群中
	5.散列片键：
		适用 大量查询中使用使用升序键，但同时又希望写入数据随机分发
			每个块内 都是_id 键升序的
		创建步骤： 
			 创建索引：db.users.ensureIndex({"username":"hashed"}) 
			  指定 散列片键： sh.shardCollection("app.users",{"username":"hashed"})	
			散列片键 不能使用 unique 选项 
	6.通过指定分片 tag ,并指定该 tag 的范围，所有处于该范围的文档将保存在该tag标记的分片上
		同一个tag 可由多个分片绑定， 一个分片可以绑定多个tag  
		sh.addShardTag(shard, tag)
	
		sh.addShardTag("shard0000", "NYC")
		sh.addShardTag("shard0001", "LAX")
		sh.addShardTag("shard0002", "NRT")
		指定范围：
		 sh.addTagRange("namespace",最小值,最大值,"tag")
		其中  namespace 指定 集合的全限定名，
			
		sh.addTagRange( "exampledb.collection",
                { state: "NY", zip: MinKey },
                { state: "NY", zip: MaxKey },
                "NY"
              )	
		
		当通过 MinKey 和MaxKey 表示范围，则指定的集合的所有文档都会保存到 该tag 标记的分片
		sh.addTagRange("test.large",{name:MinKey},{name:MaxKey},"tag1")	
		其中 name 为片键名

2017-09-19T10:46:06.266+0800 I REPL     [rsSync] oplog sync 1 of 3
2017-09-19T10:46:06.266+0800 I REPL     [rsSync] oplog sync 2 of 3
2017-09-19T10:46:06.266+0800 I REPL     [rsSync] initial sync building indexes
2017-09-19T10:46:06.266+0800 I REPL     [rsSync] initial sync cloning indexes for : admin
2017-09-19T10:46:06.267+0800 I STORAGE  [rsSync] copying indexes for: { name: "system.version", type: "collection", options: {}, info: { readOnly: false }, idIndex: { v: 1, key: { _id: 1 }, name: "_id_", ns: "admin.system.version" } }
2017-09-19T10:46:06.268+0800 E REPL     [rsSync] 22 Attempt to use a decimal BSON type when experimental decimal server support is not currently enabled.
2017-09-19T10:46:06.268+0800 E REPL     [rsSync] initial sync attempt failed, 0 attempts remaining
2017-09-19T10:46:07.253+0800 I REPL     [ReplicationExecutor] could not find member to sync from
2017-09-19T10:46:11.268+0800 F REPL     [rsSync] The maximum number of retries have been exhausted for initial sync.
2017-09-19T10:46:11.269+0800 I -        [rsSync] Fatal Assertion 16233

查看网络连接：
	可以使用connPoolStats命令，查看mongos和mongod之间的连接信息：db.adminCommand({"connPoolStats":1})	

	在一个分片上执行connPoolStats，输出信息中可以看到该分片与其他分片间的连接，包括连接到其他分片做数据迁移的连接

限制连接数量： 
		可在mongos的命令行配置中使用maxConns选项，这样可以限制mongos能够创建的连接数量。
		可以使用下面公式计算分片能够处理的来自单一mongos连接数量：

                              maxConns = 20000 - (mongos进程的数量 * 3 ) - (每个副本集的成员数量 * 3 ) - (其他/mongos进程的数量)

			其中：
				(mongos进程的数量 * 3 ) 每个 mongos 会为每个mongod 创建3个连接：
						一个用于转发客户端请求，一个用于追踪错误信息，即写回监听， 一个监控副本集状态
				 (每个副本集的成员数量 * 3 ) 主节点与每个备份节点创建一个连接， 每个备份节点会与主节点创建两个连接
				(其他/mongos进程的数量) 值其他可能连接到 mongod 的进程数			
			maxConns 只能阻止 mongos 创建多于该值的连接数，但不能出来连接耗尽，
				当连接耗尽时，则请求会发生阻塞
                              MongoDB如果没有安全退出，那些已经打开的套接字很可能没有被关闭。
				当执行操作时，会遇到错误，并刷新连接，因此可能会出现大量重新连接，此时除了重启进程，没有其他特殊有效的方法

删除分片： 需在admin 上执行 db.runCommand({removeShard:"shard_name"})	
		 
		保证 均衡器开启
		均衡器会将该分片上的所有块移至到其他分片上，块在移动时可能会被拆分
		然后在块迁移后， 若仍有数据库以该分片为主分片时，则需在删除分片前将这些数据库移除
			db.adminCommand({movePrimary:"blog",to:"other_shard"})
		再次执行 db.runCommand({removeShard:"shard_name"})
		在移除某个分片过程中，可以执行 db.runCommand({removeShard:"shard_name"}) 多次，查看当前状态